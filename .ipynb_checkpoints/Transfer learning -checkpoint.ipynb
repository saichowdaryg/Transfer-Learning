{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submission for CV Coding Challenge, for summer internship at Step.ai\n",
    "\n",
    "- Name   :  Sai Chowdary Gullapally\n",
    "- Contact:  \n",
    "   - scgullap@eng.ucsd.edu\n",
    "   - 858-729-8482  \n",
    "\n",
    "- Coded in Python 3 (images downloading function needs to be tweaked a bit for python 2)\n",
    "- Libraries: Keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim: Build a classifier to classify the Images corresponding to three classes given at the following URL's:\n",
    "1. Class One\n",
    "  - http://image-net.org/api/text/imagenet.synset.geturls?wnid=n02084071\n",
    "2. Class Two\n",
    "  - http://image-net.org/api/text/imagenet.synset.geturls?wnid=n02121808\n",
    "3. Class Three\n",
    "  - http://image-net.org/api/text/imagenet.synset.geturls?wnid=n00007846\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach: Transfer Learning\n",
    "\n",
    "Why Transfer Learning?\n",
    "- Models like VGG-16 have already been trained on huge datasets using GPU's for weeks and are very accurate.\n",
    "- These pretrained models are readily available in all popular deep learning libraries, we use Keras as it makes our work quite easy.(Note: In my computer Keras has TensorFlow as backend).\n",
    "- We can make use of these pretrained models, the initial layers in these model can be used are very good feature extractors, so we can retain the initial layers and slightly modify the layers in later stages and train them or fine tune them to get good results, also as the number of parameters to be trained is quite small, we will have to use only a few samples per each category for training.\n",
    "- **This combined with another trick we shall see after a while eliminates the need of using GPU's and saves a lot of time as the training is quite fast.**\n",
    "\n",
    "Alternative approach:\n",
    "- Building our own convolutional network.\n",
    "- But even with this dataset as the images vary a lot within each class, we will require atleast a moderate sized network and that means having to use GPU's and training for long times and even then results will not be as good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Acquisition Pipeline\n",
    "#### Function: download_images(filename,num_images) \n",
    "\n",
    "Arguments:\n",
    "1. A  \".txt\" file\n",
    "2. The number of images to be downloaded for that category\n",
    "\n",
    "What does the function do?\n",
    "- The function downloads the specified number of images for each category into folders with the same name as the filename\n",
    "\n",
    "Obtaining the \".txt\" files:\n",
    "- I went to the links provided for the datasets and manually copied the URL's for images of each category into a separate \".txt\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading URL's from category1.txt\n",
      "Total number of URL's is: 1604\n",
      "Creating folder for downloading the images\n",
      "Starting to download first 1000 existing images into 'data' folder...................\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Reading URL's from category2.txt\n",
      "Total number of URL's is: 1832\n",
      "Creating folder for downloading the images\n",
      "Starting to download first 1000 existing images into 'data' folder...................\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Reading URL's from category3.txt\n",
      "Total number of URL's is: 1243\n",
      "Creating folder for downloading the images\n",
      "Starting to download first 1000 existing images into 'data' folder...................\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
     ]
    }
   ],
   "source": [
    "#function to download the images\n",
    "#References\n",
    "#http://www.gadgetcluster.com/2014/07/download-images-from-urls-using-python/\n",
    "#http://stackoverflow.com/questions/17960942/attributeerror-module-object-has-no-attribute-urlretrieve\n",
    "def download_images(filename,num_img):       \n",
    "    print(\"Reading URL's from \"+filename+\".txt\")\n",
    "    lines = open(filename+\".txt\",\"r\").read().split(\"\\n\")\n",
    "    print(\"Total number of URL's is: %d\"%len(lines))\n",
    "    print(\"Creating folder for downloading the images\")\n",
    "    os.makedirs(filename)\n",
    "    print(\"Starting to download first %d existing images into 'data' folder...................\"%num_img)\n",
    "    count=0\n",
    "    path=os.getcwd()\n",
    "    for line in lines:\n",
    "        if count<num_img:            \n",
    "            try:                   \n",
    "                URL= line\n",
    "                IMAGE = URL.rsplit('/',1)[1]\n",
    "                fullfilename = os.path.join(path,filename, IMAGE)\n",
    "                urlretrieve(URL, fullfilename)\n",
    "                if count%10==0:\n",
    "                    print(\">\",end=\"\")\n",
    "                count=count+1\n",
    "            except:   \n",
    "                pass\n",
    "        else:\n",
    "            break\n",
    "    return\n",
    "download_images('category1',1000)\n",
    "print()\n",
    "download_images('category2',1000)\n",
    "print()\n",
    "download_images('category3',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img,img_to_array,load_img\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD,Adam,RMSprop\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note 1:\n",
    "After the images were downloaded upon manual inspection I found that there were a lot of blank images like the one shown below:\n",
    "![alt text](blank_resized.jpg \"blank images\")\n",
    "- These and a other similar kinds of \"noise\" is present in data for all categories, as we only use small training set I manually deleted these, in future I plan to use a self detecter function to delete these kinds images automatically(we could identify these images based on the amoutnt of white space in the image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note 2: Very Important\n",
    "- For the code to work we need create a new folder 'data'(I have already done this part) and put the three folders created for each category into it. I will automate this in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path from which data will be taken\n",
      "C:\\Users\\Sai\\Documents\\deep_learning-master\\Sai_submission\\data\n"
     ]
    }
   ],
   "source": [
    "path=os.getcwd()\n",
    "folder='data'\n",
    "path1=os.path.join(path,folder)\n",
    "print(\"Path from which data will be taken\")\n",
    "print(path1)\n",
    "#path1=r'C:\\Users\\Sai\\Documents\\deep_learning-master\\data'\n",
    "#path2=r'C:\\Users\\Sai\\Documents\\deep_learning-master\\used_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the images from the folders for preparing the training data: \n",
    "- We read *samples_per_class* images from each category for the training data and create corresponding labels\n",
    "   - Here I am using only **130 images per each category** because we use transfer learning so we will not be needing many samples, as we are in a way **trying to fine tune a model trained to detect objects and importantly objects of similar nature so it is justified to take only a few samples** \n",
    "- In fact as we only have three categories we need not use this many images as well but as we have enough images its always a good idea to use more data so I used this many! \n",
    "- We read *20* images from each category for validation data and create corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed reading training, validation data\n"
     ]
    }
   ],
   "source": [
    "folders_list=os.listdir(path1)\n",
    "count=0;\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "x_valid=[]\n",
    "y_valid=[]\n",
    "samples_per_class=130\n",
    "for iter1 in folders_list:\n",
    "    image_folder_path=path1+'\\\\'+iter1\n",
    "    images_list=os.listdir(image_folder_path)\n",
    "    images_chopped_list=images_list[0:samples_per_class]\n",
    "    for i in images_chopped_list:\n",
    "        img = image.load_img(image_folder_path+'\\\\'+i, target_size=(224, 224))\n",
    "        #img.save(path2+'\\\\'+ i, \"JPEG\")\n",
    "        img=image.img_to_array(img)\n",
    "        x_train.append(img)\n",
    "        y_train.append(count)    \n",
    "    images_chopped_list=images_list[samples_per_class:samples_per_class+20]\n",
    "    for i in images_chopped_list:\n",
    "        img = image.load_img(image_folder_path+'\\\\'+i, target_size=(224, 224))\n",
    "        #img.save(path2+'\\\\'+ i, \"JPEG\")\n",
    "        img=image.img_to_array(img)\n",
    "        x_valid.append(img)\n",
    "        y_valid.append(count)\n",
    "        \n",
    "    count=count+1\n",
    "print(\"completed reading training, validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dim = 3\n",
    "x_train=preprocess_input(np.array(x_train))\n",
    "x_train=x_train/255\n",
    "x_valid=preprocess_input(np.array(x_valid))\n",
    "x_valid=x_valid/255\n",
    "y_train=np.array(np_utils.to_categorical(y_train,output_dim))\n",
    "y_valid=np.array(np_utils.to_categorical(y_valid,output_dim))\n",
    "data_list=[x_train,y_train,x_valid,y_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have all the data ready, we now begin the model pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 2: Model Pipeline\n",
    "#### Note: I have experimented with many models, *only one of them must be executed* if both are executed the results obtained will correspond to the latest executed model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: \n",
    "- We download the VGG16 model with weights trained on ImageNet and modify it, we remove the last soft max layer (and later put a new softmax layer after a few blocks of code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 4096)          16781312    fc1[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "[x_train,y_train,x_valid,y_valid]=data_list\n",
    "vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "vgg_out = vgg_model.layers[-2].output #Last FC layer's output \n",
    "\n",
    "#Create softmax layer taking input as vgg_out\n",
    "#Create new transfer learning model\n",
    "fprop = Model(input=vgg_model.input, output=vgg_out)\n",
    "fprop.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: \n",
    "- We retain the entire VGG16 model with weights trained on ImageNet (and later put a new softmax layer after a few blocks of code) , i.e we use representation of representations model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 4096)          16781312    fc1[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 1000)          4097000     fc2[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "[x_train,y_train,x_valid,y_valid]=data_list\n",
    "vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "vgg_out = vgg_model.layers[-1].output #Last FC layer's output \n",
    "\n",
    "#Create softmax layer taking input as vgg_out\n",
    "#Create new transfer learning model\n",
    "fprop = Model(input=vgg_model.input, output=vgg_out)\n",
    "fprop.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: \n",
    "- We download the VGG16 model with weights trained on ImageNet and modify it, we remove the last soft max layer and also the layer before it  (and later put a new softmax layer after a few blocks of code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 117,479,232\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "[x_train,y_train,x_valid,y_valid]=data_list\n",
    "vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "vgg_out = vgg_model.layers[-3].output #Last FC layer's output \n",
    "\n",
    "#Create softmax layer taking input as vgg_out\n",
    "#Create new transfer learning model\n",
    "fprop = Model(input=vgg_model.input, output=vgg_out)\n",
    "fprop.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fprop is the part of the model which is pretrained, as this part is not trained, we can forward prop the entire input throughthis and then store the output of this part in a numpy array and save it. Now in the next part we can just make a new network which has these values as input and then just one softmax layer, thus reducing the time and allowing us to train on huge datasets (though not needed here as we only have three categories) without the necessity of GPU's\n",
    "- the code below shows how we are saving the \"new\" representation of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 468s   \n",
      "60/60 [==============================] - 73s    \n"
     ]
    }
   ],
   "source": [
    "train_features=fprop.predict(x_train,batch_size=8,verbose=1)\n",
    "np.save('train_features',train_features)\n",
    "np.save('train_labels',y_train)\n",
    "valid_features=fprop.predict(x_valid,batch_size=8,verbose=1)\n",
    "np.save('valid_features',valid_features)\n",
    "np.save('valid_labels',y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now from the next time if we need to make a few changes to parameters of the model etc, we need not run the acode for data generatio part again we can we can just start of from the below block where we load the numpy arrays of training and validation data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features=np.load('train_features.npy')\n",
    "y_train=np.load('train_labels.npy')\n",
    "valid_features=np.load('valid_features.npy')\n",
    "y_valid=np.load('valid_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once loading of the data is done we complete the model by adding a softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_2 (Dense)                  (None, 3)             12291       dense_input_2[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 12,291\n",
      "Trainable params: 12,291\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#select model\n",
    "\n",
    "#model 1\n",
    "inp_size=4096\n",
    "\n",
    "#model 2\n",
    "#inp_size=1000\n",
    "\n",
    "#model 3\n",
    "#inp_size=4096\n",
    "\n",
    "#model 4: I put two trainable softmax layers (dim 1000 followed by dim 3), \n",
    "#        it is giving  alsmost same results as model 1  so i did not pursue it further\n",
    "#inp_size=4096\n",
    "\n",
    "tl_model=Sequential()\n",
    "tl_model.add(Dense(output_dim,input_dim=inp_size,activation='softmax'))\n",
    "#only for model 4(need to change the first layer as well)\n",
    "#tl_model.add(Dense(output_dim,activation='softmax'))\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training the model (pretty much straight forward!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 390 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 3s - loss: 1.9985 - acc: 0.3487 - val_loss: 1.1089 - val_acc: 0.3833\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 0s - loss: 1.1155 - acc: 0.4667 - val_loss: 1.8719 - val_acc: 0.5167\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 0s - loss: 1.2142 - acc: 0.4667 - val_loss: 1.3819 - val_acc: 0.3667\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 0s - loss: 0.9225 - acc: 0.6103 - val_loss: 1.2275 - val_acc: 0.4333\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 0s - loss: 0.9927 - acc: 0.5821 - val_loss: 0.7747 - val_acc: 0.6333\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 0s - loss: 0.8834 - acc: 0.5923 - val_loss: 0.8067 - val_acc: 0.6667\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 0s - loss: 0.8545 - acc: 0.6564 - val_loss: 1.1656 - val_acc: 0.5667\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 0s - loss: 0.8471 - acc: 0.6103 - val_loss: 0.7789 - val_acc: 0.6833\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 0s - loss: 0.7243 - acc: 0.6974 - val_loss: 1.0237 - val_acc: 0.6500\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 0s - loss: 0.8272 - acc: 0.6205 - val_loss: 0.8891 - val_acc: 0.5500\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 0s - loss: 0.7375 - acc: 0.6846 - val_loss: 0.9539 - val_acc: 0.5667\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 0s - loss: 0.6381 - acc: 0.7282 - val_loss: 1.5166 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 0s - loss: 0.7839 - acc: 0.6744 - val_loss: 1.4112 - val_acc: 0.4833\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 0s - loss: 0.5590 - acc: 0.7410 - val_loss: 1.7766 - val_acc: 0.4167\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 0s - loss: 0.7028 - acc: 0.7179 - val_loss: 0.9282 - val_acc: 0.6167\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 0s - loss: 0.6348 - acc: 0.7128 - val_loss: 1.3162 - val_acc: 0.5167\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 0s - loss: 0.6652 - acc: 0.7026 - val_loss: 1.0423 - val_acc: 0.5833\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 0s - loss: 0.6470 - acc: 0.7308 - val_loss: 0.7089 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 0s - loss: 0.6239 - acc: 0.7385 - val_loss: 0.8744 - val_acc: 0.7167\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 0s - loss: 0.6510 - acc: 0.7231 - val_loss: 1.2265 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 0s - loss: 0.7072 - acc: 0.7179 - val_loss: 0.6449 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 0s - loss: 0.5302 - acc: 0.7769 - val_loss: 0.9809 - val_acc: 0.7333\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 0s - loss: 0.5951 - acc: 0.7615 - val_loss: 0.9798 - val_acc: 0.6833\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 0s - loss: 0.6220 - acc: 0.7231 - val_loss: 0.7626 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 0s - loss: 0.4844 - acc: 0.7769 - val_loss: 0.7852 - val_acc: 0.6667\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 0s - loss: 0.5601 - acc: 0.7846 - val_loss: 0.9362 - val_acc: 0.7167\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 0s - loss: 0.5602 - acc: 0.7718 - val_loss: 1.1427 - val_acc: 0.6167\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 0s - loss: 0.5780 - acc: 0.7487 - val_loss: 0.6818 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 0s - loss: 0.4903 - acc: 0.7897 - val_loss: 0.8708 - val_acc: 0.6167\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 0s - loss: 0.5952 - acc: 0.7436 - val_loss: 0.7646 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 0s - loss: 0.4750 - acc: 0.7795 - val_loss: 1.7421 - val_acc: 0.6500\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 0s - loss: 0.5478 - acc: 0.7718 - val_loss: 1.1745 - val_acc: 0.5667\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 0s - loss: 0.5330 - acc: 0.7923 - val_loss: 0.7940 - val_acc: 0.7667\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 0s - loss: 0.4905 - acc: 0.7667 - val_loss: 0.6647 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 0s - loss: 0.5010 - acc: 0.7923 - val_loss: 0.7660 - val_acc: 0.6500\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 0s - loss: 0.4366 - acc: 0.8000 - val_loss: 0.8728 - val_acc: 0.7333\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 0s - loss: 0.5242 - acc: 0.7949 - val_loss: 1.4972 - val_acc: 0.5500\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 0s - loss: 0.4251 - acc: 0.8308 - val_loss: 0.6842 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 0s - loss: 0.4132 - acc: 0.8333 - val_loss: 0.9800 - val_acc: 0.7167\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 0s - loss: 0.4176 - acc: 0.8256 - val_loss: 0.7544 - val_acc: 0.7667\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 0s - loss: 0.4623 - acc: 0.8103 - val_loss: 0.8051 - val_acc: 0.6667\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 0s - loss: 0.4271 - acc: 0.7923 - val_loss: 1.1375 - val_acc: 0.5833\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 0s - loss: 0.4716 - acc: 0.8051 - val_loss: 0.7573 - val_acc: 0.7833\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 0s - loss: 0.3851 - acc: 0.8436 - val_loss: 0.7861 - val_acc: 0.6833\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 0s - loss: 0.4136 - acc: 0.8333 - val_loss: 0.7877 - val_acc: 0.6833\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 0s - loss: 0.3859 - acc: 0.8333 - val_loss: 0.6743 - val_acc: 0.7167\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 0s - loss: 0.4524 - acc: 0.8282 - val_loss: 0.9306 - val_acc: 0.6667\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 0s - loss: 0.4583 - acc: 0.8026 - val_loss: 0.9018 - val_acc: 0.7667\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 0s - loss: 0.4392 - acc: 0.8231 - val_loss: 0.6715 - val_acc: 0.7833\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 0s - loss: 0.4240 - acc: 0.8308 - val_loss: 0.8277 - val_acc: 0.7333\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 0s - loss: 0.3537 - acc: 0.8590 - val_loss: 0.6928 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 0s - loss: 0.3809 - acc: 0.8410 - val_loss: 0.7389 - val_acc: 0.7167\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 0s - loss: 0.3266 - acc: 0.8667 - val_loss: 1.3514 - val_acc: 0.5833\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 0s - loss: 0.4218 - acc: 0.8282 - val_loss: 0.7061 - val_acc: 0.7500\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 0s - loss: 0.3626 - acc: 0.8538 - val_loss: 0.7216 - val_acc: 0.7333\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 0s - loss: 0.4270 - acc: 0.8154 - val_loss: 0.9277 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 0s - loss: 0.3896 - acc: 0.8308 - val_loss: 0.7182 - val_acc: 0.7500\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 0s - loss: 0.3546 - acc: 0.8667 - val_loss: 0.7407 - val_acc: 0.7500\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 0s - loss: 0.3776 - acc: 0.8333 - val_loss: 0.9356 - val_acc: 0.6667\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 0s - loss: 0.2949 - acc: 0.8872 - val_loss: 0.7606 - val_acc: 0.7667\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 0s - loss: 0.3862 - acc: 0.8487 - val_loss: 1.4035 - val_acc: 0.6167\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 0s - loss: 0.3352 - acc: 0.8641 - val_loss: 0.8949 - val_acc: 0.7500\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 0s - loss: 0.3348 - acc: 0.8821 - val_loss: 0.8330 - val_acc: 0.7333\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 0s - loss: 0.3896 - acc: 0.8564 - val_loss: 0.7531 - val_acc: 0.7833\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 0s - loss: 0.2737 - acc: 0.8897 - val_loss: 0.7185 - val_acc: 0.7333\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 0s - loss: 0.3643 - acc: 0.8513 - val_loss: 0.7868 - val_acc: 0.7833\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 0s - loss: 0.3371 - acc: 0.8590 - val_loss: 0.7747 - val_acc: 0.7833\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 0s - loss: 0.3324 - acc: 0.8564 - val_loss: 0.7766 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 0s - loss: 0.3114 - acc: 0.8487 - val_loss: 0.7396 - val_acc: 0.7833\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 0s - loss: 0.2602 - acc: 0.8974 - val_loss: 0.9835 - val_acc: 0.6500\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 0s - loss: 0.3411 - acc: 0.8692 - val_loss: 0.8598 - val_acc: 0.7667\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 0s - loss: 0.2810 - acc: 0.9026 - val_loss: 0.9215 - val_acc: 0.7167\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 0s - loss: 0.3194 - acc: 0.8744 - val_loss: 0.7446 - val_acc: 0.7667\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 0s - loss: 0.3364 - acc: 0.8410 - val_loss: 0.7021 - val_acc: 0.7500\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 0s - loss: 0.2844 - acc: 0.8795 - val_loss: 1.1648 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 0s - loss: 0.2840 - acc: 0.8897 - val_loss: 0.8375 - val_acc: 0.7667\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 0s - loss: 0.2843 - acc: 0.8846 - val_loss: 0.9282 - val_acc: 0.7667\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 0s - loss: 0.2638 - acc: 0.9077 - val_loss: 0.8756 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 0s - loss: 0.2763 - acc: 0.8795 - val_loss: 0.7337 - val_acc: 0.7667\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 0s - loss: 0.3146 - acc: 0.8692 - val_loss: 0.9224 - val_acc: 0.6667\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 0s - loss: 0.2929 - acc: 0.8692 - val_loss: 0.9392 - val_acc: 0.7833\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 0s - loss: 0.3019 - acc: 0.8718 - val_loss: 0.7228 - val_acc: 0.7500\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 0s - loss: 0.2532 - acc: 0.8897 - val_loss: 1.1654 - val_acc: 0.7500\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 0s - loss: 0.2832 - acc: 0.8744 - val_loss: 0.7345 - val_acc: 0.7833\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 0s - loss: 0.2277 - acc: 0.9051 - val_loss: 1.3647 - val_acc: 0.6667\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 0s - loss: 0.2687 - acc: 0.8897 - val_loss: 0.7465 - val_acc: 0.7333\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 0s - loss: 0.2813 - acc: 0.8923 - val_loss: 0.8463 - val_acc: 0.6833\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 0s - loss: 0.2626 - acc: 0.8821 - val_loss: 0.7991 - val_acc: 0.7833\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 0s - loss: 0.2543 - acc: 0.8872 - val_loss: 0.9820 - val_acc: 0.6333\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 0s - loss: 0.2778 - acc: 0.8949 - val_loss: 0.7678 - val_acc: 0.7833\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 0s - loss: 0.2633 - acc: 0.9026 - val_loss: 0.8675 - val_acc: 0.7167\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 0s - loss: 0.3004 - acc: 0.8795 - val_loss: 0.9049 - val_acc: 0.6833\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 0s - loss: 0.2397 - acc: 0.9128 - val_loss: 0.8102 - val_acc: 0.7500\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 0s - loss: 0.3265 - acc: 0.8641 - val_loss: 0.8495 - val_acc: 0.7833\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 0s - loss: 0.2293 - acc: 0.9077 - val_loss: 0.8232 - val_acc: 0.7833\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 0s - loss: 0.1798 - acc: 0.9462 - val_loss: 1.4561 - val_acc: 0.6667\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 0s - loss: 0.2612 - acc: 0.8897 - val_loss: 0.9220 - val_acc: 0.7667\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 0s - loss: 0.3512 - acc: 0.8949 - val_loss: 0.7536 - val_acc: 0.7833\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 0s - loss: 0.2035 - acc: 0.9179 - val_loss: 1.1613 - val_acc: 0.6000\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 0s - loss: 0.2777 - acc: 0.8769 - val_loss: 1.0007 - val_acc: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6180336be0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['acc'])\n",
    "tl_model.fit(train_features,y_train,batch_size=22,validation_data=(valid_features,y_valid),nb_epoch=100,verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "Test image:\n",
    "![alt text](test.jpg \"test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs list, here I just take one input \n",
    "x_test=[]\n",
    "#Note: here for simplicity I am just using a single image, but we can put a loop and take multiple images as before\n",
    "img = image.load_img(os.getcwd()+'\\\\test.jpg', target_size=(224, 224))\n",
    "img=image.img_to_array(img)\n",
    "x_test.append(img)\n",
    "x_test=preprocess_input(np.array(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the image of a dog. Time taken for prediction is 2.868860 second(s).\n"
     ]
    }
   ],
   "source": [
    "#no need to make a new model unnecessarily\n",
    "from time import time\n",
    "\n",
    "t1=time()\n",
    "x=fprop.predict(x_test)\n",
    "y=tl_model.predict(x)\n",
    "category=np.argmax(y, axis=1)\n",
    "if category[0]==0:\n",
    "    print(\"This is the image of a dog.\",end=\"\")\n",
    "elif category[0]==1:\n",
    "    print(\"This is the image of a cat.\",end=\"\")\n",
    "else:\n",
    "    print(\"This is the image of a human.\",end=\"\")\n",
    "t2=time()\n",
    "print(\" Time taken for prediction is %f second(s).\"%(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "epochs:100, batch size:22, 130 samples per category\n",
    "- With Model 1: upto 79% validation accuracy, upto 92% training accuracy (I have tried for 500 epochs, at that point training accuracy goes to 100% or almost 100% BUT validation accuracy remains more or less in 72%-78% range i.e the model is perhaps in the overtraining mode and as the validation accuracy is what we are interested in I just trained for 100 epochs )\n",
    "- With Model 2: upto 46% validation accuracy, upto 52% training accuracy \n",
    "- With Model 3: upto 40% validation accuracy, upto 46% training accuracy\n",
    "- The time taken for prediction is around 3 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "- We can see that with Model 1 (Model 4 also gives same results) we get pretty good results i.e almost 80%, this is pretty much as expected because we are using the VGG16 which has been trained on imagenet for many days, we just change the output softmax layer to fit our needs. \n",
    "- With Model 2 first we get the predictions of the VGG16 net and then we try classifying based on these into 3 categories, it is possible that the latter layers are more representative fot the entire data VGG was trained on and as a result they are not giving good results\n",
    "- With Model 3 we remove an enttire layer completely i.e we reduce the depth of the network and as suggested in ablation studies the eror percentage i very high.\n",
    "- I also experimented adding an additional trainable layer in between as compensation of the removal of one of the layers but surprisingly it did not improve results, I have yet to analyze why this is happening.\n",
    "\n",
    "## Improving the results:\n",
    "- Cearly the more data we add the better results we will get BUT this should be decided upon the application we want to use the network for as that will determine the level of accuracy demanded.\n",
    "- We can use custom networks by starting from scratch and training them but this is much quicker and will give almost as good a result if not better, as the custom ones we train.\n",
    "- We can kind of crop various (224,224) sections of the input images and feed this as inputs, or we can do global contrast normalization etc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Other Achitectures:\n",
    "\n",
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 230, 230, 3)   0           input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Convolution2D)            (None, 112, 112, 64)  9472        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 112, 112, 64)  256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 112, 112, 64)  0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 55, 55, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Convolution2D)   (None, 55, 55, 64)    4160        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Convolution2D)   (None, 55, 55, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Convolution2D)   (None, 55, 55, 256)   16640       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Convolution2D)    (None, 55, 55, 256)   16640       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 55, 55, 256)   1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 55, 55, 256)   0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 55, 55, 256)   0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Convolution2D)   (None, 55, 55, 64)    16448       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Convolution2D)   (None, 55, 55, 64)    36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Convolution2D)   (None, 55, 55, 256)   16640       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 55, 55, 256)   0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 55, 55, 256)   0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Convolution2D)   (None, 55, 55, 64)    16448       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Convolution2D)   (None, 55, 55, 64)    36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Convolution2D)   (None, 55, 55, 256)   16640       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 55, 55, 256)   0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 55, 55, 256)   0           merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Convolution2D)   (None, 28, 28, 128)   32896       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Convolution2D)   (None, 28, 28, 128)   147584      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Convolution2D)   (None, 28, 28, 512)   66048       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Convolution2D)    (None, 28, 28, 512)   131584      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 28, 28, 512)   2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 28, 28, 512)   0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 28, 28, 512)   0           merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Convolution2D)   (None, 28, 28, 128)   65664       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Convolution2D)   (None, 28, 28, 128)   147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Convolution2D)   (None, 28, 28, 512)   66048       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 28, 28, 512)   0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 28, 28, 512)   0           merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Convolution2D)   (None, 28, 28, 128)   65664       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Convolution2D)   (None, 28, 28, 128)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Convolution2D)   (None, 28, 28, 512)   66048       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 28, 28, 512)   0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 28, 28, 512)   0           merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Convolution2D)   (None, 28, 28, 128)   65664       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Convolution2D)   (None, 28, 28, 128)   147584      activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Convolution2D)   (None, 28, 28, 512)   66048       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 28, 28, 512)   0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 28, 28, 512)   0           merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Convolution2D)   (None, 14, 14, 256)   131328      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Convolution2D)   (None, 14, 14, 256)   590080      activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Convolution2D)   (None, 14, 14, 1024)  263168      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Convolution2D)    (None, 14, 14, 1024)  525312      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 14, 14, 1024)  4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 14, 14, 1024)  0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 14, 14, 1024)  0           merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Convolution2D)   (None, 14, 14, 256)   262400      activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Convolution2D)   (None, 14, 14, 256)   590080      activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Convolution2D)   (None, 14, 14, 1024)  263168      activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 14, 14, 1024)  0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 14, 14, 1024)  0           merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Convolution2D)   (None, 14, 14, 256)   262400      activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Convolution2D)   (None, 14, 14, 256)   590080      activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Convolution2D)   (None, 14, 14, 1024)  263168      activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 14, 14, 1024)  0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 14, 14, 1024)  0           merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Convolution2D)   (None, 14, 14, 256)   262400      activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Convolution2D)   (None, 14, 14, 256)   590080      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Convolution2D)   (None, 14, 14, 1024)  263168      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 14, 14, 1024)  0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 14, 14, 1024)  0           merge_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Convolution2D)   (None, 14, 14, 256)   262400      activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Convolution2D)   (None, 14, 14, 256)   590080      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Convolution2D)   (None, 14, 14, 1024)  263168      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 14, 14, 1024)  0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 14, 14, 1024)  0           merge_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Convolution2D)   (None, 14, 14, 256)   262400      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Convolution2D)   (None, 14, 14, 256)   590080      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Convolution2D)   (None, 14, 14, 1024)  263168      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_13 (Merge)                 (None, 14, 14, 1024)  0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 14, 14, 1024)  0           merge_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Convolution2D)   (None, 7, 7, 512)     524800      activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Convolution2D)   (None, 7, 7, 512)     2359808     activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Convolution2D)   (None, 7, 7, 2048)    1050624     activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Convolution2D)    (None, 7, 7, 2048)    2099200     activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, 7, 7, 2048)    8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_14 (Merge)                 (None, 7, 7, 2048)    0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 7, 7, 2048)    0           merge_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Convolution2D)   (None, 7, 7, 512)     1049088     activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Convolution2D)   (None, 7, 7, 512)     2359808     activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Convolution2D)   (None, 7, 7, 2048)    1050624     activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_15 (Merge)                 (None, 7, 7, 2048)    0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 7, 7, 2048)    0           merge_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Convolution2D)   (None, 7, 7, 512)     1049088     activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Convolution2D)   (None, 7, 7, 512)     2359808     activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Convolution2D)   (None, 7, 7, 2048)    1050624     activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_16 (Merge)                 (None, 7, 7, 2048)    0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 7, 7, 2048)    0           merge_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2048)          0           avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "[x_train,y_train,x_valid,y_valid]=data_list\n",
    "\n",
    "resnet = ResNet50(weights='imagenet')\n",
    "resnet_out = resnet.layers[-2].output #Last FC layer's output \n",
    "\n",
    "#Create softmax layer taking input as vgg_out\n",
    "#Create new transfer learning model\n",
    "fprop = Model(input=resnet.input, output=resnet_out)\n",
    "fprop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 271s   \n",
      "60/60 [==============================] - 40s    \n"
     ]
    }
   ],
   "source": [
    "train_features=fprop.predict(x_train,batch_size=8,verbose=1)\n",
    "np.save('train_features',train_features)\n",
    "np.save('train_labels',y_train)\n",
    "valid_features=fprop.predict(x_valid,batch_size=8,verbose=1)\n",
    "np.save('valid_features',valid_features)\n",
    "np.save('valid_labels',y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features=np.load('train_features.npy')\n",
    "y_train=np.load('train_labels.npy')\n",
    "valid_features=np.load('valid_features.npy')\n",
    "y_valid=np.load('valid_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_25 (Dense)                 (None, 3)             6147        dense_input_18[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 6,147\n",
      "Trainable params: 6,147\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp_size=2048\n",
    "tl_model=Sequential()\n",
    "tl_model.add(Dense(output_dim,input_dim=inp_size,activation='softmax'))\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 390 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 3s - loss: 0.5900 - acc: 0.7923 - val_loss: 1.2086 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 0s - loss: 0.5718 - acc: 0.8179 - val_loss: 1.2380 - val_acc: 0.4333\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 0s - loss: 0.5711 - acc: 0.8231 - val_loss: 1.2277 - val_acc: 0.4833\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 0s - loss: 0.5712 - acc: 0.8231 - val_loss: 1.1395 - val_acc: 0.4167\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 0s - loss: 0.5653 - acc: 0.8026 - val_loss: 1.1545 - val_acc: 0.4333\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 0s - loss: 0.5744 - acc: 0.8000 - val_loss: 1.1997 - val_acc: 0.4500\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 0s - loss: 0.5728 - acc: 0.8103 - val_loss: 1.1336 - val_acc: 0.4167\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 0s - loss: 0.5680 - acc: 0.8128 - val_loss: 1.1335 - val_acc: 0.4167\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 0s - loss: 0.5724 - acc: 0.8077 - val_loss: 1.1433 - val_acc: 0.4333\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 0s - loss: 0.5706 - acc: 0.8051 - val_loss: 1.1349 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 0s - loss: 0.5776 - acc: 0.8154 - val_loss: 1.1627 - val_acc: 0.4667\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 0s - loss: 0.5697 - acc: 0.8000 - val_loss: 1.1483 - val_acc: 0.4333\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 0s - loss: 0.5630 - acc: 0.7974 - val_loss: 1.2231 - val_acc: 0.4167\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 0s - loss: 0.5690 - acc: 0.8051 - val_loss: 1.1632 - val_acc: 0.4167\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 0s - loss: 0.5728 - acc: 0.8128 - val_loss: 1.1466 - val_acc: 0.4167\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 0s - loss: 0.5670 - acc: 0.8154 - val_loss: 1.1778 - val_acc: 0.4333\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 0s - loss: 0.5739 - acc: 0.7923 - val_loss: 1.1463 - val_acc: 0.4167\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 0s - loss: 0.5736 - acc: 0.8103 - val_loss: 1.1516 - val_acc: 0.4500\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 0s - loss: 0.5666 - acc: 0.8051 - val_loss: 1.1813 - val_acc: 0.4167\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 0s - loss: 0.5678 - acc: 0.8282 - val_loss: 1.1413 - val_acc: 0.3667\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 0s - loss: 0.5690 - acc: 0.8128 - val_loss: 1.1589 - val_acc: 0.4167\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 0s - loss: 0.5656 - acc: 0.8179 - val_loss: 1.1355 - val_acc: 0.3667\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 0s - loss: 0.5723 - acc: 0.8231 - val_loss: 1.1888 - val_acc: 0.4500\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 0s - loss: 0.5686 - acc: 0.8179 - val_loss: 1.1747 - val_acc: 0.4333\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 0s - loss: 0.5731 - acc: 0.7974 - val_loss: 1.1517 - val_acc: 0.4667\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 0s - loss: 0.5680 - acc: 0.8077 - val_loss: 1.1331 - val_acc: 0.3833\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 0s - loss: 0.5644 - acc: 0.8051 - val_loss: 1.1938 - val_acc: 0.4667\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 0s - loss: 0.5724 - acc: 0.8179 - val_loss: 1.1481 - val_acc: 0.4333\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 0s - loss: 0.5712 - acc: 0.8051 - val_loss: 1.1560 - val_acc: 0.4333\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 0s - loss: 0.5679 - acc: 0.8179 - val_loss: 1.1412 - val_acc: 0.4167\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 0s - loss: 0.5624 - acc: 0.8051 - val_loss: 1.1812 - val_acc: 0.4333\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 0s - loss: 0.5662 - acc: 0.8333 - val_loss: 1.1714 - val_acc: 0.4667\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 0s - loss: 0.5717 - acc: 0.8051 - val_loss: 1.1537 - val_acc: 0.4333\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 0s - loss: 0.5721 - acc: 0.7949 - val_loss: 1.1634 - val_acc: 0.4500\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 0s - loss: 0.5599 - acc: 0.8308 - val_loss: 1.1806 - val_acc: 0.4333\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 0s - loss: 0.5756 - acc: 0.8205 - val_loss: 1.1394 - val_acc: 0.3833\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 0s - loss: 0.5607 - acc: 0.8103 - val_loss: 1.1386 - val_acc: 0.4167\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 0s - loss: 0.5685 - acc: 0.8026 - val_loss: 1.2015 - val_acc: 0.4333\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 0s - loss: 0.5653 - acc: 0.7974 - val_loss: 1.1688 - val_acc: 0.4500\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 0s - loss: 0.5578 - acc: 0.8231 - val_loss: 1.2793 - val_acc: 0.4167\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 0s - loss: 0.5671 - acc: 0.8128 - val_loss: 1.1907 - val_acc: 0.4500\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 0s - loss: 0.5657 - acc: 0.8308 - val_loss: 1.1754 - val_acc: 0.4500\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 0s - loss: 0.5640 - acc: 0.8026 - val_loss: 1.1705 - val_acc: 0.4167\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 0s - loss: 0.5668 - acc: 0.8026 - val_loss: 1.1762 - val_acc: 0.4500\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 0s - loss: 0.5622 - acc: 0.8128 - val_loss: 1.1689 - val_acc: 0.4500\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 0s - loss: 0.5679 - acc: 0.8077 - val_loss: 1.1378 - val_acc: 0.3667\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 0s - loss: 0.5620 - acc: 0.8128 - val_loss: 1.1475 - val_acc: 0.4333\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 0s - loss: 0.5636 - acc: 0.8179 - val_loss: 1.1893 - val_acc: 0.4500\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 0s - loss: 0.5716 - acc: 0.8103 - val_loss: 1.1589 - val_acc: 0.4500\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 0s - loss: 0.5653 - acc: 0.8103 - val_loss: 1.1845 - val_acc: 0.4333\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 0s - loss: 0.5549 - acc: 0.8103 - val_loss: 1.3436 - val_acc: 0.4333\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 0s - loss: 0.5699 - acc: 0.8026 - val_loss: 1.1730 - val_acc: 0.4000\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 0s - loss: 0.5571 - acc: 0.8179 - val_loss: 1.1353 - val_acc: 0.3833\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 0s - loss: 0.5666 - acc: 0.8128 - val_loss: 1.2312 - val_acc: 0.4333\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 0s - loss: 0.5749 - acc: 0.8026 - val_loss: 1.1396 - val_acc: 0.3833\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 0s - loss: 0.5639 - acc: 0.8154 - val_loss: 1.1427 - val_acc: 0.3667\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 0s - loss: 0.5648 - acc: 0.7923 - val_loss: 1.1650 - val_acc: 0.4833\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 0s - loss: 0.5682 - acc: 0.7949 - val_loss: 1.1956 - val_acc: 0.4167\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 0s - loss: 0.5647 - acc: 0.8077 - val_loss: 1.1761 - val_acc: 0.4500\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 0s - loss: 0.5669 - acc: 0.8103 - val_loss: 1.1759 - val_acc: 0.4833\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 0s - loss: 0.5650 - acc: 0.8154 - val_loss: 1.1362 - val_acc: 0.4000\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 0s - loss: 0.5569 - acc: 0.8179 - val_loss: 1.1482 - val_acc: 0.4167\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 0s - loss: 0.5668 - acc: 0.8077 - val_loss: 1.1367 - val_acc: 0.3833\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 0s - loss: 0.5683 - acc: 0.8128 - val_loss: 1.1536 - val_acc: 0.4667\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 0s - loss: 0.5537 - acc: 0.8077 - val_loss: 1.2593 - val_acc: 0.4333\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 0s - loss: 0.5677 - acc: 0.8282 - val_loss: 1.1832 - val_acc: 0.4833\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 0s - loss: 0.5549 - acc: 0.8256 - val_loss: 1.1600 - val_acc: 0.4333\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 0s - loss: 0.5632 - acc: 0.8154 - val_loss: 1.1458 - val_acc: 0.4000\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 0s - loss: 0.5635 - acc: 0.8128 - val_loss: 1.1427 - val_acc: 0.4000\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 0s - loss: 0.5637 - acc: 0.8128 - val_loss: 1.1386 - val_acc: 0.3833\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 0s - loss: 0.5610 - acc: 0.8128 - val_loss: 1.1415 - val_acc: 0.4167\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 0s - loss: 0.5622 - acc: 0.8256 - val_loss: 1.1615 - val_acc: 0.4500\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 0s - loss: 0.5600 - acc: 0.8128 - val_loss: 1.1568 - val_acc: 0.4833\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 0s - loss: 0.5656 - acc: 0.7974 - val_loss: 1.2089 - val_acc: 0.4167\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 0s - loss: 0.5543 - acc: 0.8308 - val_loss: 1.1357 - val_acc: 0.4000\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 0s - loss: 0.5691 - acc: 0.7949 - val_loss: 1.1392 - val_acc: 0.3833\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 0s - loss: 0.5581 - acc: 0.8077 - val_loss: 1.1458 - val_acc: 0.4333\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 0s - loss: 0.5570 - acc: 0.8103 - val_loss: 1.1459 - val_acc: 0.4333\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 0s - loss: 0.5630 - acc: 0.8077 - val_loss: 1.1429 - val_acc: 0.4167\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 0s - loss: 0.5592 - acc: 0.8231 - val_loss: 1.1357 - val_acc: 0.4000\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 0s - loss: 0.5517 - acc: 0.8077 - val_loss: 1.1710 - val_acc: 0.4667\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 0s - loss: 0.5615 - acc: 0.8051 - val_loss: 1.1669 - val_acc: 0.4833\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 0s - loss: 0.5613 - acc: 0.8205 - val_loss: 1.1870 - val_acc: 0.4500\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 0s - loss: 0.5575 - acc: 0.8205 - val_loss: 1.1549 - val_acc: 0.4667\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 0s - loss: 0.5629 - acc: 0.8077 - val_loss: 1.1724 - val_acc: 0.4833\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 0s - loss: 0.5573 - acc: 0.8154 - val_loss: 1.1435 - val_acc: 0.3667\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 0s - loss: 0.5625 - acc: 0.8103 - val_loss: 1.1523 - val_acc: 0.4500\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 0s - loss: 0.5592 - acc: 0.8154 - val_loss: 1.1414 - val_acc: 0.4167\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 0s - loss: 0.5578 - acc: 0.8308 - val_loss: 1.1621 - val_acc: 0.4500\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 0s - loss: 0.5549 - acc: 0.8077 - val_loss: 1.1900 - val_acc: 0.4500\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 0s - loss: 0.5551 - acc: 0.8154 - val_loss: 1.1400 - val_acc: 0.4167\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 0s - loss: 0.5633 - acc: 0.8385 - val_loss: 1.1986 - val_acc: 0.4500\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 0s - loss: 0.5680 - acc: 0.8077 - val_loss: 1.1787 - val_acc: 0.4500\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 0s - loss: 0.5543 - acc: 0.8077 - val_loss: 1.1898 - val_acc: 0.4667\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 0s - loss: 0.5627 - acc: 0.8179 - val_loss: 1.1512 - val_acc: 0.4167\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 0s - loss: 0.5555 - acc: 0.8103 - val_loss: 1.1888 - val_acc: 0.4833\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 0s - loss: 0.5581 - acc: 0.8179 - val_loss: 1.1504 - val_acc: 0.4333\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 0s - loss: 0.5527 - acc: 0.8154 - val_loss: 1.1558 - val_acc: 0.4500\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 0s - loss: 0.5510 - acc: 0.8077 - val_loss: 1.1822 - val_acc: 0.4500\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 0s - loss: 0.5593 - acc: 0.8077 - val_loss: 1.1528 - val_acc: 0.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2178f29b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['acc'])\n",
    "tl_model.fit(train_features,y_train,batch_size=22,validation_data=(valid_features,y_valid),nb_epoch=100,verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussions:\n",
    "- 1500 epochs \n",
    "- Training accuracy 75% \n",
    "- validation accuracy 47% \n",
    "- Discussion: Here the number of parameters to finetune are half a smany as we had in VGG16 (fully connected layers of dimension 4096 vs 2048) perhaps that must be why we do not have good performance, if we start modifying the convolutional layers then as there  are a lot of filters we will have toomany parameters which might lead to overfitting and also computationally it gets expensive so for  out case VGG is better than ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "Inception has input image shape (229,229), but our images are (224,224). There is a custom input shape option for inception but it was giving me some error which I htink will take a while for me to debug so for our experiment with architectre I directly read the images again in (299,299) format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed reading training, validation data\n"
     ]
    }
   ],
   "source": [
    "folders_list=os.listdir(path1)\n",
    "count=0;\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "x_valid=[]\n",
    "y_valid=[]\n",
    "samples_per_class=130\n",
    "for iter1 in folders_list:\n",
    "    image_folder_path=path1+'\\\\'+iter1\n",
    "    images_list=os.listdir(image_folder_path)\n",
    "    images_chopped_list=images_list[0:samples_per_class]\n",
    "    for i in images_chopped_list:\n",
    "        img = image.load_img(image_folder_path+'\\\\'+i, target_size=(299, 299))\n",
    "        #img.save(path2+'\\\\'+ i, \"JPEG\")\n",
    "        img=image.img_to_array(img)\n",
    "        x_train.append(img)\n",
    "        y_train.append(count)    \n",
    "    images_chopped_list=images_list[samples_per_class:samples_per_class+20]\n",
    "    for i in images_chopped_list:\n",
    "        img = image.load_img(image_folder_path+'\\\\'+i, target_size=(299, 299))\n",
    "        #img.save(path2+'\\\\'+ i, \"JPEG\")\n",
    "        img=image.img_to_array(img)\n",
    "        x_valid.append(img)\n",
    "        y_valid.append(count)\n",
    "        \n",
    "    count=count+1\n",
    "print(\"completed reading training, validation data\")\n",
    "\n",
    "output_dim = 3\n",
    "x_train=preprocess_input(np.array(x_train))\n",
    "x_train=x_train/255\n",
    "x_valid=preprocess_input(np.array(x_valid))\n",
    "x_valid=x_valid/255\n",
    "y_train=np.array(np_utils.to_categorical(y_train,output_dim))\n",
    "y_valid=np.array(np_utils.to_categorical(y_valid,output_dim))\n",
    "data_list=[x_train,y_train,x_valid,y_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 299, 299, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 149, 149, 32)  896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 149, 149, 32)  128         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 147, 147, 32)  9248        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 147, 147, 32)  128         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 147, 147, 64)  18496       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 147, 147, 64)  256         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 73, 73, 64)    0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 73, 73, 80)    5200        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 73, 73, 80)    320         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 71, 71, 192)   138432      batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 71, 71, 192)   768         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 35, 35, 192)   0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 35, 35, 64)    12352       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 35, 35, 64)    256         convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 35, 35, 48)    9264        maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 35, 35, 96)    55392       batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 35, 35, 48)    192         convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 35, 35, 96)    384         convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_1 (AveragePooli (None, 35, 35, 192)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 35, 35, 64)    12352       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 35, 35, 64)    76864       batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 35, 35, 96)    83040       batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 35, 35, 32)    6176        averagepooling2d_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 35, 35, 64)    256         convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 35, 35, 64)    256         convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 35, 35, 96)    384         convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 35, 35, 32)    128         convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Merge)                   (None, 35, 35, 256)   0           batchnormalization_6[0][0]       \n",
      "                                                                   batchnormalization_8[0][0]       \n",
      "                                                                   batchnormalization_11[0][0]      \n",
      "                                                                   batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 35, 35, 64)    16448       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorm (None, 35, 35, 64)    256         convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 35, 35, 48)    12336       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 35, 35, 96)    55392       batchnormalization_16[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorm (None, 35, 35, 48)    192         convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorm (None, 35, 35, 96)    384         convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_2 (AveragePooli (None, 35, 35, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 35, 35, 64)    16448       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 35, 35, 64)    76864       batchnormalization_14[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 35, 35, 96)    83040       batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 35, 35, 32)    8224        averagepooling2d_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNorm (None, 35, 35, 64)    256         convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorm (None, 35, 35, 64)    256         convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorm (None, 35, 35, 96)    384         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorm (None, 35, 35, 32)    128         convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Merge)                   (None, 35, 35, 256)   0           batchnormalization_13[0][0]      \n",
      "                                                                   batchnormalization_15[0][0]      \n",
      "                                                                   batchnormalization_18[0][0]      \n",
      "                                                                   batchnormalization_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 35, 35, 64)    16448       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_23 (BatchNorm (None, 35, 35, 64)    256         convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 35, 35, 48)    12336       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 35, 35, 96)    55392       batchnormalization_23[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_21 (BatchNorm (None, 35, 35, 48)    192         convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_24 (BatchNorm (None, 35, 35, 96)    384         convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_3 (AveragePooli (None, 35, 35, 256)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 35, 35, 64)    16448       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 35, 35, 64)    76864       batchnormalization_21[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 35, 35, 96)    83040       batchnormalization_24[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 35, 35, 32)    8224        averagepooling2d_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorm (None, 35, 35, 64)    256         convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 35, 35, 64)    256         convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_25 (BatchNorm (None, 35, 35, 96)    384         convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_26 (BatchNorm (None, 35, 35, 32)    128         convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Merge)                   (None, 35, 35, 256)   0           batchnormalization_20[0][0]      \n",
      "                                                                   batchnormalization_22[0][0]      \n",
      "                                                                   batchnormalization_25[0][0]      \n",
      "                                                                   batchnormalization_26[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 35, 35, 64)    16448       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_28 (BatchNorm (None, 35, 35, 64)    256         convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 35, 35, 96)    55392       batchnormalization_28[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_29 (BatchNorm (None, 35, 35, 96)    384         convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 17, 17, 384)   885120      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_30 (Convolution2D) (None, 17, 17, 96)    83040       batchnormalization_29[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_27 (BatchNorm (None, 17, 17, 384)   1536        convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_30 (BatchNorm (None, 17, 17, 96)    384         convolution2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 256)   0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Merge)                   (None, 17, 17, 736)   0           batchnormalization_27[0][0]      \n",
      "                                                                   batchnormalization_30[0][0]      \n",
      "                                                                   maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_35 (Convolution2D) (None, 17, 17, 128)   94336       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_35 (BatchNorm (None, 17, 17, 128)   512         convolution2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_36 (Convolution2D) (None, 17, 17, 128)   114816      batchnormalization_35[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_36 (BatchNorm (None, 17, 17, 128)   512         convolution2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_32 (Convolution2D) (None, 17, 17, 128)   94336       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_37 (Convolution2D) (None, 17, 17, 128)   114816      batchnormalization_36[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_32 (BatchNorm (None, 17, 17, 128)   512         convolution2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_37 (BatchNorm (None, 17, 17, 128)   512         convolution2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_33 (Convolution2D) (None, 17, 17, 128)   114816      batchnormalization_32[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_38 (Convolution2D) (None, 17, 17, 128)   114816      batchnormalization_37[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_33 (BatchNorm (None, 17, 17, 128)   512         convolution2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_38 (BatchNorm (None, 17, 17, 128)   512         convolution2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_4 (AveragePooli (None, 17, 17, 736)   0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_31 (Convolution2D) (None, 17, 17, 192)   141504      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_34 (Convolution2D) (None, 17, 17, 192)   172224      batchnormalization_33[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 17, 17, 192)   172224      batchnormalization_38[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_40 (Convolution2D) (None, 17, 17, 192)   141504      averagepooling2d_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_31 (BatchNorm (None, 17, 17, 192)   768         convolution2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_34 (BatchNorm (None, 17, 17, 192)   768         convolution2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_39 (BatchNorm (None, 17, 17, 192)   768         convolution2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_40 (BatchNorm (None, 17, 17, 192)   768         convolution2d_40[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Merge)                   (None, 17, 17, 768)   0           batchnormalization_31[0][0]      \n",
      "                                                                   batchnormalization_34[0][0]      \n",
      "                                                                   batchnormalization_39[0][0]      \n",
      "                                                                   batchnormalization_40[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_45 (Convolution2D) (None, 17, 17, 160)   123040      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_45 (BatchNorm (None, 17, 17, 160)   640         convolution2d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_46 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_45[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_46 (BatchNorm (None, 17, 17, 160)   640         convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_42 (Convolution2D) (None, 17, 17, 160)   123040      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_47 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_46[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_42 (BatchNorm (None, 17, 17, 160)   640         convolution2d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_47 (BatchNorm (None, 17, 17, 160)   640         convolution2d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_43 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_42[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_48 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_47[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_43 (BatchNorm (None, 17, 17, 160)   640         convolution2d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_48 (BatchNorm (None, 17, 17, 160)   640         convolution2d_48[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_5 (AveragePooli (None, 17, 17, 768)   0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_41 (Convolution2D) (None, 17, 17, 192)   147648      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_44 (Convolution2D) (None, 17, 17, 192)   215232      batchnormalization_43[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_49 (Convolution2D) (None, 17, 17, 192)   215232      batchnormalization_48[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_50 (Convolution2D) (None, 17, 17, 192)   147648      averagepooling2d_5[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_41 (BatchNorm (None, 17, 17, 192)   768         convolution2d_41[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_44 (BatchNorm (None, 17, 17, 192)   768         convolution2d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_49 (BatchNorm (None, 17, 17, 192)   768         convolution2d_49[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_50 (BatchNorm (None, 17, 17, 192)   768         convolution2d_50[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Merge)                   (None, 17, 17, 768)   0           batchnormalization_41[0][0]      \n",
      "                                                                   batchnormalization_44[0][0]      \n",
      "                                                                   batchnormalization_49[0][0]      \n",
      "                                                                   batchnormalization_50[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_55 (Convolution2D) (None, 17, 17, 160)   123040      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_55 (BatchNorm (None, 17, 17, 160)   640         convolution2d_55[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_56 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_55[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_56 (BatchNorm (None, 17, 17, 160)   640         convolution2d_56[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_52 (Convolution2D) (None, 17, 17, 160)   123040      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_57 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_56[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_52 (BatchNorm (None, 17, 17, 160)   640         convolution2d_52[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_57 (BatchNorm (None, 17, 17, 160)   640         convolution2d_57[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_53 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_52[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_58 (Convolution2D) (None, 17, 17, 160)   179360      batchnormalization_57[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_53 (BatchNorm (None, 17, 17, 160)   640         convolution2d_53[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_58 (BatchNorm (None, 17, 17, 160)   640         convolution2d_58[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_6 (AveragePooli (None, 17, 17, 768)   0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_51 (Convolution2D) (None, 17, 17, 192)   147648      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_54 (Convolution2D) (None, 17, 17, 192)   215232      batchnormalization_53[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_59 (Convolution2D) (None, 17, 17, 192)   215232      batchnormalization_58[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_60 (Convolution2D) (None, 17, 17, 192)   147648      averagepooling2d_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_51 (BatchNorm (None, 17, 17, 192)   768         convolution2d_51[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_54 (BatchNorm (None, 17, 17, 192)   768         convolution2d_54[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_59 (BatchNorm (None, 17, 17, 192)   768         convolution2d_59[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_60 (BatchNorm (None, 17, 17, 192)   768         convolution2d_60[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Merge)                   (None, 17, 17, 768)   0           batchnormalization_51[0][0]      \n",
      "                                                                   batchnormalization_54[0][0]      \n",
      "                                                                   batchnormalization_59[0][0]      \n",
      "                                                                   batchnormalization_60[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_65 (Convolution2D) (None, 17, 17, 160)   123040      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_65 (BatchNorm (None, 17, 17, 160)   640         convolution2d_65[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_66 (Convolution2D) (None, 17, 17, 192)   215232      batchnormalization_65[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_66 (BatchNorm (None, 17, 17, 192)   768         convolution2d_66[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_62 (Convolution2D) (None, 17, 17, 192)   147648      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_67 (Convolution2D) (None, 17, 17, 192)   258240      batchnormalization_66[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_62 (BatchNorm (None, 17, 17, 192)   768         convolution2d_62[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_67 (BatchNorm (None, 17, 17, 192)   768         convolution2d_67[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_63 (Convolution2D) (None, 17, 17, 192)   258240      batchnormalization_62[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_68 (Convolution2D) (None, 17, 17, 192)   258240      batchnormalization_67[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_63 (BatchNorm (None, 17, 17, 192)   768         convolution2d_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_68 (BatchNorm (None, 17, 17, 192)   768         convolution2d_68[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_7 (AveragePooli (None, 17, 17, 768)   0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_61 (Convolution2D) (None, 17, 17, 192)   147648      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_64 (Convolution2D) (None, 17, 17, 192)   258240      batchnormalization_63[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_69 (Convolution2D) (None, 17, 17, 192)   258240      batchnormalization_68[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_70 (Convolution2D) (None, 17, 17, 192)   147648      averagepooling2d_7[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_61 (BatchNorm (None, 17, 17, 192)   768         convolution2d_61[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_64 (BatchNorm (None, 17, 17, 192)   768         convolution2d_64[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_69 (BatchNorm (None, 17, 17, 192)   768         convolution2d_69[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_70 (BatchNorm (None, 17, 17, 192)   768         convolution2d_70[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Merge)                   (None, 17, 17, 768)   0           batchnormalization_61[0][0]      \n",
      "                                                                   batchnormalization_64[0][0]      \n",
      "                                                                   batchnormalization_69[0][0]      \n",
      "                                                                   batchnormalization_70[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_73 (Convolution2D) (None, 17, 17, 192)   147648      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_73 (BatchNorm (None, 17, 17, 192)   768         convolution2d_73[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_74 (Convolution2D) (None, 17, 17, 192)   258240      batchnormalization_73[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_74 (BatchNorm (None, 17, 17, 192)   768         convolution2d_74[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_71 (Convolution2D) (None, 17, 17, 192)   147648      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_75 (Convolution2D) (None, 17, 17, 192)   258240      batchnormalization_74[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_71 (BatchNorm (None, 17, 17, 192)   768         convolution2d_71[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_75 (BatchNorm (None, 17, 17, 192)   768         convolution2d_75[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_72 (Convolution2D) (None, 8, 8, 320)     553280      batchnormalization_71[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_76 (Convolution2D) (None, 8, 8, 192)     331968      batchnormalization_75[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_72 (BatchNorm (None, 8, 8, 320)     1280        convolution2d_72[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_76 (BatchNorm (None, 8, 8, 192)     768         convolution2d_76[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_8 (AveragePooli (None, 8, 8, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Merge)                   (None, 8, 8, 1280)    0           batchnormalization_72[0][0]      \n",
      "                                                                   batchnormalization_76[0][0]      \n",
      "                                                                   averagepooling2d_8[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_81 (Convolution2D) (None, 8, 8, 448)     573888      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_81 (BatchNorm (None, 8, 8, 448)     1792        convolution2d_81[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_78 (Convolution2D) (None, 8, 8, 384)     491904      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_82 (Convolution2D) (None, 8, 8, 384)     1548672     batchnormalization_81[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_78 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_78[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_82 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_82[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_79 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_78[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_80 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_78[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_83 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_82[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_84 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_82[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_9 (AveragePooli (None, 8, 8, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_77 (Convolution2D) (None, 8, 8, 320)     409920      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_79 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_79[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_80 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_80[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_83 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_83[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_84 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_84[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_85 (Convolution2D) (None, 8, 8, 192)     245952      averagepooling2d_9[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_77 (BatchNorm (None, 8, 8, 320)     1280        convolution2d_77[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Merge)                 (None, 8, 8, 768)     0           batchnormalization_79[0][0]      \n",
      "                                                                   batchnormalization_80[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 8, 8, 768)     0           batchnormalization_83[0][0]      \n",
      "                                                                   batchnormalization_84[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_85 (BatchNorm (None, 8, 8, 192)     768         convolution2d_85[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Merge)                   (None, 8, 8, 2048)    0           batchnormalization_77[0][0]      \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   merge_1[0][0]                    \n",
      "                                                                   batchnormalization_85[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_90 (Convolution2D) (None, 8, 8, 448)     917952      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_90 (BatchNorm (None, 8, 8, 448)     1792        convolution2d_90[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_87 (Convolution2D) (None, 8, 8, 384)     786816      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_91 (Convolution2D) (None, 8, 8, 384)     1548672     batchnormalization_90[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_87 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_87[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_91 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_91[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_88 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_87[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_89 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_87[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_92 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_91[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_93 (Convolution2D) (None, 8, 8, 384)     442752      batchnormalization_91[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_10 (AveragePool (None, 8, 8, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_86 (Convolution2D) (None, 8, 8, 320)     655680      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_88 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_88[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_89 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_89[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_92 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_92[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_93 (BatchNorm (None, 8, 8, 384)     1536        convolution2d_93[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_94 (Convolution2D) (None, 8, 8, 192)     393408      averagepooling2d_10[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_86 (BatchNorm (None, 8, 8, 320)     1280        convolution2d_86[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Merge)                 (None, 8, 8, 768)     0           batchnormalization_88[0][0]      \n",
      "                                                                   batchnormalization_89[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 8, 8, 768)     0           batchnormalization_92[0][0]      \n",
      "                                                                   batchnormalization_93[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_94 (BatchNorm (None, 8, 8, 192)     768         convolution2d_94[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Merge)                  (None, 8, 8, 2048)    0           batchnormalization_86[0][0]      \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   merge_2[0][0]                    \n",
      "                                                                   batchnormalization_94[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 2048)          0           avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 21,611,968\n",
      "Trainable params: 21,577,728\n",
      "Non-trainable params: 34,240\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "\n",
    "[x_train,y_train,x_valid,y_valid]=data_list\n",
    "inception = InceptionV3(weights='imagenet', include_top=True)\n",
    "inception_out = inception.layers[-2].output #Last FC layer's output \n",
    "\n",
    "#Create softmax layer taking input as vgg_out\n",
    "#Create new transfer learning model\n",
    "fprop = Model(input=inception.input, output=inception_out)\n",
    "fprop.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 307s   \n",
      "60/60 [==============================] - 44s    \n"
     ]
    }
   ],
   "source": [
    "train_features=fprop.predict(x_train,batch_size=8,verbose=1)\n",
    "np.save('train_features',train_features)\n",
    "np.save('train_labels',y_train)\n",
    "valid_features=fprop.predict(x_valid,batch_size=8,verbose=1)\n",
    "np.save('valid_features',valid_features)\n",
    "np.save('valid_labels',y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features=np.load('train_features.npy')\n",
    "y_train=np.load('train_labels.npy')\n",
    "valid_features=np.load('valid_features.npy')\n",
    "y_valid=np.load('valid_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 3)             6147        dense_input_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 6,147\n",
      "Trainable params: 6,147\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp_size=2048\n",
    "tl_model=Sequential()\n",
    "tl_model.add(Dense(output_dim,input_dim=inp_size,activation='softmax'))\n",
    "#tl_model.add(Dense(3,activation='softmax'))\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 390 samples, validate on 60 samples\n",
      "Epoch 1/20\n",
      "390/390 [==============================] - 1s - loss: 0.5008 - acc: 0.8179 - val_loss: 0.5976 - val_acc: 0.8167\n",
      "Epoch 2/20\n",
      "390/390 [==============================] - 0s - loss: 0.2233 - acc: 0.9308 - val_loss: 0.5041 - val_acc: 0.8333\n",
      "Epoch 3/20\n",
      "390/390 [==============================] - 0s - loss: 0.1541 - acc: 0.9487 - val_loss: 0.5199 - val_acc: 0.8333\n",
      "Epoch 4/20\n",
      "390/390 [==============================] - 0s - loss: 0.1083 - acc: 0.9718 - val_loss: 0.4806 - val_acc: 0.8167\n",
      "Epoch 5/20\n",
      "390/390 [==============================] - 0s - loss: 0.0766 - acc: 0.9769 - val_loss: 0.5016 - val_acc: 0.8333\n",
      "Epoch 6/20\n",
      "390/390 [==============================] - 0s - loss: 0.0495 - acc: 0.9923 - val_loss: 0.5298 - val_acc: 0.8167\n",
      "Epoch 7/20\n",
      "390/390 [==============================] - 0s - loss: 0.0388 - acc: 0.9923 - val_loss: 0.5341 - val_acc: 0.8333\n",
      "Epoch 8/20\n",
      "390/390 [==============================] - 0s - loss: 0.0290 - acc: 0.9949 - val_loss: 0.5216 - val_acc: 0.8500\n",
      "Epoch 9/20\n",
      "390/390 [==============================] - 0s - loss: 0.0214 - acc: 0.9974 - val_loss: 0.5607 - val_acc: 0.8333\n",
      "Epoch 10/20\n",
      "390/390 [==============================] - 0s - loss: 0.0226 - acc: 0.9949 - val_loss: 0.5577 - val_acc: 0.8500\n",
      "Epoch 11/20\n",
      "390/390 [==============================] - 0s - loss: 0.0157 - acc: 0.9949 - val_loss: 0.5983 - val_acc: 0.8333\n",
      "Epoch 12/20\n",
      "390/390 [==============================] - 0s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.5514 - val_acc: 0.8500\n",
      "Epoch 13/20\n",
      "390/390 [==============================] - 0s - loss: 0.0165 - acc: 0.9949 - val_loss: 0.5925 - val_acc: 0.8500\n",
      "Epoch 14/20\n",
      "390/390 [==============================] - 0s - loss: 0.0121 - acc: 0.9974 - val_loss: 0.6408 - val_acc: 0.8333\n",
      "Epoch 15/20\n",
      "390/390 [==============================] - 0s - loss: 0.0106 - acc: 0.9974 - val_loss: 0.6094 - val_acc: 0.8500\n",
      "Epoch 16/20\n",
      "390/390 [==============================] - 0s - loss: 0.0130 - acc: 0.9949 - val_loss: 0.6195 - val_acc: 0.8500\n",
      "Epoch 17/20\n",
      "390/390 [==============================] - 0s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.6775 - val_acc: 0.8333\n",
      "Epoch 18/20\n",
      "390/390 [==============================] - 0s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.6394 - val_acc: 0.8500\n",
      "Epoch 19/20\n",
      "390/390 [==============================] - 0s - loss: 0.0065 - acc: 0.9974 - val_loss: 0.6895 - val_acc: 0.8333\n",
      "Epoch 20/20\n",
      "390/390 [==============================] - 0s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.6454 - val_acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x61b5628780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['acc'])\n",
    "tl_model.fit(train_features,y_train,batch_size=22,validation_data=(valid_features,y_valid),nb_epoch=20,verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "Test image:\n",
    "![alt text](test.jpg \"test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs list, here I just take one input \n",
    "x_test=[]\n",
    "#Note: here for simplicity I am just using a single image, but we can put a loop and take multiple images as before\n",
    "img = image.load_img(os.getcwd()+'\\\\test.jpg', target_size=(299, 299))\n",
    "img=image.img_to_array(img)\n",
    "x_test.append(img)\n",
    "x_test=preprocess_input(np.array(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the image of a dog. Time taken for prediction is 2.032044 second(s).\n"
     ]
    }
   ],
   "source": [
    "#no need to make a new model unnecessarily\n",
    "from time import time\n",
    "\n",
    "t1=time()\n",
    "x=fprop.predict(x_test)\n",
    "y=tl_model.predict(x)\n",
    "category=np.argmax(y, axis=1)\n",
    "if category[0]==0:\n",
    "    print(\"This is the image of a dog.\",end=\"\")\n",
    "elif category[0]==1:\n",
    "    print(\"This is the image of a cat.\",end=\"\")\n",
    "else:\n",
    "    print(\"This is the image of a human.\",end=\"\")\n",
    "t2=time()\n",
    "print(\" Time taken for prediction is %f second(s).\"%(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussions: This network is a BEAST!!!\n",
    "- 20 epochs (stays almost same after that)\n",
    "- Training accuracy 99% \n",
    "- validation accuracy 87%\n",
    "- The learning is much much faster than in the case of VGG model\n",
    "- Discussion: Clearly this gives us the best performance so far! The speed of convergence expected as they use Deep Supervision hence we can easily avoid the vanishing gradient problem, also the impressive accuracy must be attributed to the very deep model of inception.\n",
    "- I tweaked around the model a bit by adding extra layers etc but there was not muxh of an improvement in the resuls.\n",
    "- So from the results it seems that InceptionV3 is the best network for the task!\n",
    "- The time taken for prediction is around 2 second. This is a bit counter intuitive actually as I had expected inception to take slightly longer time as it has many layers but perhaps as the number of parameters are very few we observe this but this is interesting and I will look further into it."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
